appType: HTTP #"HTTP", "gRPC", "Task", "Kafka"
logLevel: 6
logFile: "mylogfile.log"
servies_name: test


redis:
  - name: test22
    host : 127.0.0.1
    port : 6379
    password:
    db : 0
    poolSize: 10

httpginServer:
  port: 9999  #服务端口
  appendPprof : true #是否在路由中添加 pprof 路由

es:
  - name: "es1"
    hosts: ["http://172.16.20.14:9200"] # ES集群的地址列表
    user: "elastic"
    pass: "k__rzue5xo6EYLB3g5f8"
    cloudid: ""
    apiKey: ""
    type: "host"  # 类型默认 host  使用用户名密码登录  cloud 使用 cloudid+apiKey 登录


kafkaProducers:
  - name: linkTrackingKafka
    brokers: ["127.0.01:9092"] # Kafka集群的地址列表
    topic: auto_LinkTracking # 默认的主题
    compression: gzip # 消息压缩方式，可选的值包括"gzip"、"snappy"、"lz4"、"zstd"、"none"
    timeout: 5000 # 发送消息的超时时间，单位为毫秒
    batchSize: 1 # 批量发送的消息数量，超过这个数量后就发送
    batchTime: 10  # 批量发送的时间间隔，超过这个时间就发送，单位为毫秒
    waitForAll: true  # 是否等待服务器所有副本都保存成功后再返回
    maxRetries: 3 # 重试的最大次数
    retryBackoff: 100  # 两次重试之间的时间间隔，单位为毫秒
    returnSuccesses: true   # 是否返回成功发送的消息
    newManualPartitioner: false  #是否手动分配分区


linkTracking:
  is_open: false  #是否开启链路追踪
  kafka_producer_name: linkTrackingKafka #对应推送 kafka 地址
  
auto: 123344