appType: HTTP #"HTTP", "gRPC", "Task", "Kafka"
logLevel: 1
logFile: "mylogfile.log"
servies_name: test

databases:
  - name: test
    host: 127.0.0.1
    port: 3306
    username: root
    password: root
    dbname: test
    maxIdleConns: 10
    MaxOpenConns: 10

redis:
  - name: test
    host : 127.0.0.1
    port : 6379
    password:
    db : 0
    poolSize: 10

kafkaProducers:
  - name: Producer1
    brokers: ["broker1:9092", "broker2:9092"] # Kafka集群的地址列表
    topic: test # 默认的主题
    compression: gzip # 消息压缩方式，可选的值包括"gzip"、"snappy"、"lz4"、"zstd"、"none"
    timeout: 5000 # 发送消息的超时时间，单位为毫秒
    batchSize: 500 # 批量发送的消息数量，超过这个数量后就发送
    batchTime: 5000  # 批量发送的时间间隔，超过这个时间就发送，单位为毫秒
    waitForAll: true  # 是否等待服务器所有副本都保存成功后再返回
    maxRetries: 3 # 重试的最大次数
    retryBackoff: 100  # 两次重试之间的时间间隔，单位为毫秒
    returnSuccesses: false   # 是否返回成功发送的消息
    newManualPartitioner: false  #是否手动分配分区


httpgin:
  port: 8080  #服务端口
  appendPprof : 0 #是否在路由中添加 pprof 路由


kafkaConsumers:
  - name: "Consumer1"
    brokers: ["broker1:9092", "broker2:9092"]
    topics: ["my-topic-1", "my-topic-2"]
    groupID: "my-group-1"
    autoOffsetReset: "earliest"  # 开始消费的位置，可能的值包括'earliest'、'latest'、'none'
    maxWaitTime: 500  # 从Kafka获取记录的最大等待时间（毫秒）
    sessionTimeout: 10000  # 消费者组会话的超时时间（毫秒）
    heartbeatInterval: 3000  # 心跳间隔时间（毫秒）
    
  - name: "Consumer2"
    brokers: ["broker3:9092", "broker4:9092"]
    topics: ["my-topic-3"]
    groupID: "my-group-2"
    autoOffsetReset: "earliest"  # 开始消费的位置，可能的值包括'earliest'、'latest'、'none'
    maxWaitTime: 500  # 从Kafka获取记录的最大等待时间（毫秒）
    sessionTimeout: 10000  # 消费者组会话的超时时间（毫秒）
    heartbeatInterval: 3000  # 心跳间隔时间（毫秒）


